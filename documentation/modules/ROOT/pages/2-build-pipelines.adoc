= 2. Build CI/CD Pipelines - 30 minutes
:imagesdir: ../assets/images

== Goals of this lab

The goal of this exercise is to build and deploy the modernized customer application to OpenShift using link:https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/cicd/index#op-detailed-concepts[OpenShift Pipelines^]. You will accomplish this with the following steps:

* Use the https://tekton.dev/[Tekton^] Pipeline to build and deploy the new, modernized application using Red Hat JBoss Web Server instead of Apache Tomcat as the runtime.
* Set up the configuration for the *customers* service to connect to the legacy PostgreSQL database VM which is now running on OpenShift Container Platform
* Test the *customers* service

== 2.1. Update PostgreSQL DBMS Connection using Helm

=== 2.1.1. Why OpenShift with Helm?

https://docs.openshift.com/container-platform/4.10/applications/working_with_helm_charts/understanding-helm.html[Helm^] is a package and install manager that standardizes and simplifies packaging and deployment of containerized applications with Kubernetes, anywhere in the hybrid cloud. Helm lets developers package their applications so that they can be easily shared and deployed by anyone in their organization and beyond.

Helm can also be used to automate *day-1* tasks like installation and basic configuration management for setting up the applications, and some *day-2* operations like performing some simple upgrades and rollbacks.

=== 2.1.2. Update the Helm Chart for a new JDBC configuration

The *customers* application in the OpenShift cluster currently has a connection failure because the application still tries to connect to the PostgreSQL database running on the legacy virtulization infrastructure. To fix the issue, you need to update the *JDBC* configuration that points to the migrated PostgreSQL database on OpenShift virtualization.

[IMPORTANT]
====
To save your time to go through the hands-on labs today, our SRE team has already migrated the legacy VM running PostgreSQL database to the OpenShift virtualization in the *retail-%USERID%* project.
====

The JDBC configuration is currently managed by the _Helm chart_ to automate day 1 & 2 operations for the modernized Globex retail system. Let's go back to the link:https://codeserver-codeserver-%USERID%.%SUBDOMAIN%[VS Code server^] and explore the *helm/customer-tomcat-gitops* directory.

Take a look at `secret/persistence.properties` file to understand how the Helm chart allows you to define the JDBC configuration.

image::gitops-persistence.png[gitops-persistence]

[NOTE]
====
The best developer practice for updating the *JDBC configuration* is that you change the configurations locally in VS Code server. Then, when you commit and push the changes to your Gitea repository, it will trigger the `OpenShift pipeline and GitOps` to automatically update OpenShift `ConfigMap` and `Secret` objects.
====

Access link:https://argocd-server-retail-%USERID%.%SUBDOMAIN%[ArgoCD web console^]. Click on `LOG IN VIA OPENSHIFT`:

image::argocd-login.png[argocd-login]

Use the following credentials if you haven't logged in to the OpenShift cluster before. OpenShift is already integrated with https://access.redhat.com/products/red-hat-single-sign-on/[Red Hat Single Sign On^].

image::sso_login.png[openshift_login]

* Login using your credentials:

** Username: `%USERID%`
** Password: `{openshift-password}`

* Click on *Allow selected permissions*

image::argo_authorize.png[openshift_login]


You will see that the `customers-tomcat-gitops` status is *Degraded* because the application still refers to the old database hostname (e.g.*postgresql-db-database*).

image::argocd-application-degrade.png[argocd-application-degrade]

Click on `applications`.

image::argocd-application-click-applications.png[argocd-application-click-applications]

Click on `APP DETAILS` to show the detail page for the application. Then, switch to `PARAMETER` tab and click on `EDIT`.

image::argocd-application-details.png[argocd-application-details]

Replace keys and values of `customerDatabase` with the following data that refer to the PostgreSQL virtual machine on Red Hat OpenShift. It should look like this:

* customerDatabase.hostname: `postgresql-database`
* customerDatabase.password: `redhat`

image::argocd-application-update.png[argocd-application-update]

[NOTE]
====
You probably see *user1* in the _user_ field at the bottom. The value won't be rendered to the _customers_ application by ArgoCD because it's the default value. You can see the actual value along with your username in the *VALUES* section. 
====

Click on `SAVE`, then close the popup window by clicking `X` on at the top right corner.

Now you will see the `OutOfSync` status of the `customers-tomcat-gitops` application because you just updated the application object, and it's now different from what's deployed (hence OutOfSync).

image::argocd-application-outofsync.png[argocd-application-outofsync]

Click on `SYNC`. Then, click on `SYNCHRONIZE` on the left popup window.

image::argocd-application-sync.png[argocd-application-sync]

It will take a few moments to synchronize the application. Wait for it to finish and show:

image::argocd-application-synced.png[argocd-application-synced]

Click to go back to the OpenShift web console and look at the link:https://console-openshift-console.%SUBDOMAIN%/k8s/ns/retail-%USERID%/secrets/customers-secret[customers-secret^]. 

image::argocd-application-secret-reveral.png[argocd-application-secret-reveral]

And Click on `Reveral values` to see the updated the JDBC configuration values.

image::argocd-application-secret.png[argocd-application-secret]

== 2.2. Run OpenShift Pipelines

=== 2.2.1 Why OpenShift Pipelines?

OpenShift Pipelines provides a *kubernetes-native CI/CD* framework based on https://tekton.dev[Tekton^] to design and run your pipelines, and is designed to run each step of the CI/CD pipeline in its own container, allowing each step to scale independently to meet the demands of the pipeline.

By extending Kubernetes/OpenShift with Custom Resource Definitions (CRDs), OpenShift Pipelines makes CI/CD concepts such as `pipeline`, `task`, and `step` natively in terms of increasing the scalability, security, ease of deployment capabilities of Kubernetes.

image::tekton-concept.png[tekton-concept]

The pipeline executes _tasks_ across a number of defined _steps_. There are tasks you will use that each have a single purpose:

* *Clone Repository* downloads the source code from the target Git repository.
* *Build from Source* builds the application artifact from source code. This task has been tweaked to allow selecting the target subdirectory from the repository in which the target application source is available, allowing you to have several application/components available in a single repository. *This way of versioning different services/components is highly discouraged*, as the optimal approach would be to have a dedicated repository for each component since their lifecycle should be independent. Nevertheless, this choice was made to gather all demo materials on a single repository for simplicity purposes.
* *Build Image* uses a Dockerfile packaged present in an application to build an image and push it to the target registry. The image will be tagged with the short commit hash of the source it contains.
* *Update Manifest* uses the short commit hash tag to update the application manifest in Git and point to the newly built image. Application deployment is then delegated to ArgoCD, which is continuously polling the configuration repository for changes and creates/updates all OpenShift objects accordingly.

The pipeline accepts the following parameters:

* *git-url*: URL of the target Git repository.
* *git-branch*: target branch to work with. (default: _main_)
* *app-subdir*: Subdirectory from the repository in which the application source code is stored.
* *target-namespace*: Namespace/project in which to deploy the application.
* *target-registry*: Registry to push the built image to. (default: _image-registry.openshift-image-registry.svc:5000_, i.e. the internal OpenShift container registry)

=== 2.2.2 Execute the Customers Pipelines

It is possible to configure webhooks and event listeners/triggers to automatically execute pipelines when source code commits are made.

For simplicity in this exercise, you will trigger the pipeline run manually.

Open a new browser to access the link:https://console-openshift-console.%SUBDOMAIN%/dev-pipelines/ns/cicd-%USERID%[OpenShift Pipeline^].


Then, you will see a pre-defined `java-deployment` pipeline in the `cicd-%USERID%` project in the _Developer perspective_.

Click on the pipeline.

image::ama-pipeline.png[ama-pipeline]

Click on `Start` in *Actions* dropdown to run the pipeline.

image::ama-pipeline-start.png[ama-pipeline-start]

A *PipelineRun* represents a single run of the pipeline, tied to the source code and image resources that should be used for this specific invocation.

This dialog box is where you bind the final target values for the source repo of the _build-artifact_ step, and the target namespace to deploy in the _update-manifest-and-push_ step. Update the workspaces section using the following values, and then click *Start*.

[NOTE]
====
Leave default values for the other keys such as `git-url, git-branch, app-subdir, target-namespace, and target-registry`.
====

* ws: `customers-pvc` in *PersistentVolumeClaim*

image::ama-pipeline-start-popup.png[ama-pipeline-start-popup]

As soon as you start the *java-deployment-pipeline* pipeline, a _pipelinerun_ is instantiated and pods are created to execute the tasks that are defined in the pipeline. After a few minutes, the pipeline should finish successfully. You can hover over the steps to get a quick snapshot of the stepâ€™s progress, or click on the steps to see detailed logs of the steps.

image::ama-pipeline-complete.png[ama-pipeline-complete]

=== 2.2.3 Add Labels for better Topology View

The Globex retail system has deployed multiple microservices to the OpenShift cluster. Each microservices has complex relations with the other microservices and databases. This architecture might not be immediately understandable for developers and SREs. Fortunately the OpenShift developer console provides an intuitive `topology` view with helpful labels and annotations. These labels detail the explicit relations among deployed applications in the same namespace.

Run the following commands to add labels and annotations to each deployment to show which _languages_, _frameworks_, and _runtimes_ are used for each application:

[.console-input]
[source,bash]
----
oc project retail-%USERID% && \
oc label deployment/inventory app.kubernetes.io/part-of=inventory app.openshift.io/runtime=quarkus --overwrite && \
oc label deployment/postgresql-inventory app.kubernetes.io/part-of=inventory app.openshift.io/runtime=postgresql --overwrite && \
oc annotate deployment/inventory app.openshift.io/connects-to='[{"apiVersion":"apps/v1","kind":"Deployment","name":"postgresql-inventory"}]' --overwrite && \
oc label deployment/orders app.kubernetes.io/part-of=orders app.openshift.io/runtime=spring --overwrite && \
oc label deployment/postgresql-orders app.kubernetes.io/part-of=orders app.openshift.io/runtime=postgresql --overwrite && \
oc annotate deployment/orders app.openshift.io/connects-to='[{"apiVersion":"apps/v1","kind":"Deployment","name":"postgresql-orders"}]' --overwrite && \
oc label deployment/customers app.kubernetes.io/part-of=customers app.openshift.io/runtime=tomcat --overwrite && \
oc annotate deployment/customers app.openshift.io/connects-to='[{"apiVersion":"apps/v1","kind":"VirtualMachine","name":"postgresql-database"}]' --overwrite && \
oc label deployment/ordersfrontend app.kubernetes.io/part-of=ordersfrontend app.openshift.io/runtime=nodejs --overwrite && \
oc annotate deployment/ordersfrontend app.openshift.io/connects-to=gateway --overwrite && \
oc label deployment/gateway app.kubernetes.io/part-of=gateway app.openshift.io/runtime=spring --overwrite && \
oc annotate deployment/gateway app.openshift.io/connects-to='["inventory","orders","customers",{"apiVersion":"apps/v1","kind":"Deployment","name":"customers"}]' --overwrite
----

[NOTE]
====
You might have no connection between `gateway` and `customers`. In that case, you can add the connection by dragging an arrow from `gateway` to `customers` _Dev Console_. This is a visual cue that the two are tied together.
====

Next, go back to the link:https://console-openshift-console.%SUBDOMAIN%/topology/ns/retail-%USERID%?view=graph[Topology View^] in `retail-%USERID%` project at Developer perspective, the applications deployment should appear as follows:

image::app-topology.png[app-topology]

== Congratulations!

You have built and deployed the modernized customer application to OpenShift using a CI/CD pipeline and connected the customer microservice to the new PostgreSQL database running with OpenShift Virtualization.

In the next step you will first update the `gateway` to connect to the new `customers` service using dynamic discovery (vs. static IP address).

Next, you will integrate the app with OpenShift GitOps, enabling declarative description of an application's components, and automatic synchronization of the deployed application. This is critical to
improving how software is delivered, minimizing the chance for configuration drift and enabling better auditability over time. Let's go!
